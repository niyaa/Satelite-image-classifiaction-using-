{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                 Implementation of Unet using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import glob\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cuda available? \n",
      "   True\n"
     ]
    }
   ],
   "source": [
    "print(\"Is cuda available? \\n  \", torch.cuda.is_available())\n",
    "device = torch.device('cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data path list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./train/aug/image_0_9312159.png\n",
      "./train/aug/image_0_9312159.png\n",
      "./train/image/2.png\n",
      "./train/label/2.png\n",
      "\n",
      " checking the final folder\n",
      "./train/image/2.png\n",
      "./train/label/2.png\n"
     ]
    }
   ],
   "source": [
    "#aumented data\n",
    "aug_data_folder = './train/aug*'\n",
    "aug_input_filepaths = sorted(glob.glob(os.path.join(aug_data_folder,\"image*\")))\n",
    "aug_target_filepaths = sorted(glob.glob(os.path.join(aug_data_folder,\"image*\")))\n",
    "print(aug_input_filepaths[1])\n",
    "print(aug_target_filepaths[1])\n",
    "\n",
    "#original data\n",
    "train_path = './train/image'\n",
    "label_path = './train/label'\n",
    "\n",
    "train_imgs = sorted(glob.glob(os.path.join(train_path,\"*\")))\n",
    "labels =  sorted(glob.glob(os.path.join(label_path,\"*\")))\n",
    "print(train_imgs[12])\n",
    "print(labels[12])\n",
    "\n",
    "#input_filepaths=aug_input_filepaths+train_imgs\n",
    "#target_filepaths = aug_target_filepaths + labels\n",
    "\n",
    "input_filepaths= train_imgs\n",
    "target_filepaths =  labels\n",
    "\n",
    "print(\"\\n checking the final folder\")\n",
    "print(input_filepaths[12])\n",
    "print(target_filepaths[12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of one image on with float data type in mega bytes : 1.0\n"
     ]
    }
   ],
   "source": [
    "test_img = cv2.imread(input_filepaths[12],cv2.IMREAD_UNCHANGED)\n",
    "new_shape = (test_img.shape[0],test_img.shape[1],1)\n",
    "test_img = test_img[np.newaxis,:,:]\n",
    "test_img.shape\n",
    "print(\"size of one image on with float data type in mega bytes :\",4*512*512/(1024*1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset and Dataloader objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataset and dataloader object\n",
    "\n",
    "class unet_dataset(Dataset):\n",
    "    def __init__(self,input_filepaths, target_filepaths):\n",
    "        \n",
    "        self.input_filepaths = input_filepaths\n",
    "        self.target_filepaths = target_filepaths\n",
    "        assert len(target_filepaths) == len(input_filepaths)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(input_filepaths)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img = cv2.imread(self.input_filepaths[idx],cv2.IMREAD_UNCHANGED)\n",
    "        img = img.astype(np.float32)/255\n",
    "        img = img[np.newaxis,:,:]\n",
    "        img = torch.from_numpy(img)\n",
    "        \n",
    "        target = cv2.imread(self.target_filepaths[idx],cv2.IMREAD_UNCHANGED)\n",
    "        target = target.astype(np.int64)\n",
    "\n",
    "        target = torch.from_numpy(target)\n",
    "        return img, target\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/projects/Satelite-image-classifiaction-using-ML/unet_model/source_ver1.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/projects/Satelite-image-classifiaction-using-ML/unet_model/source_ver1.ipynb#ch0000008vscode-remote?line=5'>6</a>\u001b[0m dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(train_dataset, batch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mcpu_count())\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/projects/Satelite-image-classifiaction-using-ML/unet_model/source_ver1.ipynb#ch0000008vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m \u001b[39mimport\u001b[39;00m ProfileReport\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/projects/Satelite-image-classifiaction-using-ML/unet_model/source_ver1.ipynb#ch0000008vscode-remote?line=8'>9</a>\u001b[0m profile \u001b[39m=\u001b[39m ProfileReport(df, title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPandas Profiling Report\u001b[39m\u001b[39m\"\u001b[39m, explorative\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/projects/Satelite-image-classifiaction-using-ML/unet_model/source_ver1.ipynb#ch0000008vscode-remote?line=9'>10</a>\u001b[0m profile\u001b[39m.\u001b[39mto_widgets()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "\n",
    "train_dataset = unet_dataset(input_filepaths,target_filepaths)\n",
    "print(train_dataset.__len__())\n",
    "batch_size = 1 \n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(df, title=\"Pandas Profiling Report\", explorative=True)\n",
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13756/2858341834.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  progress_bar = tqdm_notebook(dataloader)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/projects/Satelite-image-classifiaction-using-ML/unet_model/source_ver1.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/projects/Satelite-image-classifiaction-using-ML/unet_model/source_ver1.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m progress_bar \u001b[39m=\u001b[39m tqdm_notebook(dataloader)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/projects/Satelite-image-classifiaction-using-ML/unet_model/source_ver1.ipynb#ch0000009vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i,j \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(progress_bar):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/projects/Satelite-image-classifiaction-using-ML/unet_model/source_ver1.ipynb#ch0000009vscode-remote?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(i)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/__init__.py:28\u001b[0m, in \u001b[0;36mtqdm_notebook\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/__init__.py?line=23'>24</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnotebook\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm \u001b[39mas\u001b[39;00m _tqdm_notebook\n\u001b[1;32m     <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/__init__.py?line=24'>25</a>\u001b[0m warn(\u001b[39m\"\u001b[39m\u001b[39mThis function will be removed in tqdm==5.0.0\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/__init__.py?line=25'>26</a>\u001b[0m      \u001b[39m\"\u001b[39m\u001b[39mPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/__init__.py?line=26'>27</a>\u001b[0m      TqdmDeprecationWarning, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/__init__.py?line=27'>28</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _tqdm_notebook(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/notebook.py:242\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/notebook.py?line=239'>240</a>\u001b[0m unit_scale \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munit_scale \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munit_scale \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/notebook.py?line=240'>241</a>\u001b[0m total \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39m*\u001b[39m unit_scale \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal\n\u001b[0;32m--> <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/notebook.py?line=241'>242</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstatus_printer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp, total, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdesc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mncols)\n\u001b[1;32m    <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/notebook.py?line=242'>243</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontainer\u001b[39m.\u001b[39mpbar \u001b[39m=\u001b[39m proxy(\u001b[39mself\u001b[39m)\n\u001b[1;32m    <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/notebook.py?line=243'>244</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisplayed \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/notebook.py:118\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/notebook.py?line=108'>109</a>\u001b[0m \u001b[39m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/notebook.py?line=109'>110</a>\u001b[0m \u001b[39m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/notebook.py?line=110'>111</a>\u001b[0m \u001b[39m# if not total:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/notebook.py?line=114'>115</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/notebook.py?line=115'>116</a>\u001b[0m \u001b[39m# Prepare IPython progress bar\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/notebook.py?line=116'>117</a>\u001b[0m \u001b[39mif\u001b[39;00m IProgress \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# #187 #451 #558 #872\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/notebook.py?line=117'>118</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[1;32m    <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/notebook.py?line=118'>119</a>\u001b[0m \u001b[39mif\u001b[39;00m total:\n\u001b[1;32m    <a href='file:///home/aero/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/notebook.py?line=119'>120</a>\u001b[0m     pbar \u001b[39m=\u001b[39m IProgress(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39mtotal)\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm_notebook(dataloader)\n",
    "\n",
    "for i,j in enumerate(progress_bar):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "u net is a fullly convolutional network \n",
    "\n",
    "contracting path\n",
    "convulution layer\n",
    "relu layer\n",
    "max pooling\n",
    "\n",
    "expanding path\n",
    "convolution layer\n",
    "updampling layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,in_channels=1,n_classes=2,depth=5,wf=6, padding=False):\n",
    "        super(UNet,self).__init__()\n",
    "        self.depth = depth\n",
    "        self.down_path = nn.ModuleList()\n",
    "        self.up_path = nn.ModuleList()\n",
    "\n",
    "        prev_channels = in_channels\n",
    "\n",
    "        for i in range(depth):\n",
    "            self.down_path.append(UNetConvBlock(prev_channels, 2**(wf+i)))\n",
    "            \n",
    "            prev_channels = 2**(wf+i)\n",
    "            \n",
    "        for i in reversed(range(depth - 1)):\n",
    "            self.up_path.append(UNetUpBlock(prev_channels, 2** (wf + i)))\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.last = nn.Conv2d(prev_channels, n_classes, kernel_size=1)        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        blocks = []\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            x = down(x)\n",
    "            if i != len(self.down_path)-1 :\n",
    "                blocks.append(x)\n",
    "                x = F.max_pool2d(x,2) \n",
    "            \n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x = up(x, blocks[-i - 1])\n",
    "\n",
    "        \n",
    "        return self.last(x)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#building the model\n",
    "  \n",
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self,in_size, out_ch ):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "\n",
    "        block = []\n",
    "        block.append(nn.Conv2d(in_size, out_ch,kernel_size=3))\n",
    "        block.append(nn.ReLU())\n",
    "        block.append(nn.Conv2d(out_ch,out_ch,kernel_size=3))\n",
    "        block.append(nn.ReLU())\n",
    "        \n",
    "        self.block = nn.Sequential(*block)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.block(x)\n",
    "        return out  \n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self,in_size, out_size):\n",
    "        super(UNetUpBlock,self).__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv_block = UNetConvBlock(in_size, out_size)\n",
    "        \n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        return layer[\n",
    "            :, :, diff_y : (diff_y + target_size[0]), diff_x : (diff_x + target_size[1])\n",
    "        ]\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        out = self.conv_block(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_model(in_channels=1, num_output_classes=2,padding=False):\n",
    "    model = UNet(in_channels=1, n_classes=num_output_classes, wf=6, depth=5, padding=True)\n",
    "    \n",
    "    \n",
    "    # Optional, for multi GPU training and inference\n",
    "    #model = nn.DataParallel(model)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/projects/Satelite-image-classifiaction-using-ML/unet_model/source_ver1.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/projects/Satelite-image-classifiaction-using-ML/unet_model/source_ver1.ipynb#ch0000014vscode-remote?line=1'>2</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/projects/Satelite-image-classifiaction-using-ML/unet_model/source_ver1.ipynb#ch0000014vscode-remote?line=2'>3</a>\u001b[0m optim \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/projects/Satelite-image-classifiaction-using-ML/unet_model/source_ver1.ipynb#ch0000014vscode-remote?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/projects/Satelite-image-classifiaction-using-ML/unet_model/source_ver1.ipynb#ch0000014vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/projects/Satelite-image-classifiaction-using-ML/unet_model/source_ver1.ipynb#ch0000014vscode-remote?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m\"\u001b[39m, epoch)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "model = get_unet_model(in_channels = 1,padding = False)\n",
    "epochs = 1\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "model = model.to(device)\n",
    "for epoch in range(1, epochs+1):\n",
    "    print(\"Epoch\", epoch)\n",
    "    \n",
    "    epoch_losses = []\n",
    "    progress_bar = tqdm_notebook(dataloader)\n",
    "    \n",
    "    for ii, (X, target) in enumerate(progress_bar):\n",
    "        X = X.to(device)  # [N, 1, H, W]\n",
    "        print(X.size())\n",
    "        target = target.to(device)  # [N, H, W] with class indices (0, 1)\n",
    "        \n",
    "        prediction = model(X)  # [N, 2, H, W]\n",
    "        \n",
    "        loss = F.cross_entropy(prediction, target, weight=None)\n",
    "        break\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        epoch_losses.append(loss.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 324, 324])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70d752ef64504f69c17deb274eb0d43d01e7e0cd4a828138e701bf93825af2e3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
